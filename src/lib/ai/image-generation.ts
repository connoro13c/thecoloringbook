import { openai, OPENAI_MODELS } from '@/lib/openai'
import type { CompactLogger } from './compact-logger'
import type { TieredLogger } from './tiered-logger'
import type { ProgressiveLogger } from './progressive-logger'
import { createImageMetrics } from './compact-logger'

export interface GenerationResult {
  imageUrl: string
  prompt: string
  revisedPrompt?: string
  tokens?: {
    prompt: number
    completion: number
  }
}

export async function generateColoringPage(prompt: string, logger?: CompactLogger | TieredLogger | ProgressiveLogger): Promise<GenerationResult> {
  try {
    if (logger && 'updateImageProgress' in logger) {
      logger.updateImageProgress('Building prompt for gpt-image-1');
    }

    const response = await openai.images.generate({
      model: OPENAI_MODELS.ImageGen,
      prompt: prompt,
      n: 1,
      size: '1024x1024'
    })

    if (logger && 'updateImageProgress' in logger) {
      logger.updateImageProgress('Processing generated image');
    }

    const imageData = response.data?.[0]
    if (!imageData?.b64_json) {
      throw new Error('No image generated by gpt-image-1')
    }

    // Convert base64 to data URL for compatibility
    const imageUrl = `data:image/png;base64,${imageData.b64_json}`

    if (logger && 'updateImageProgress' in logger) {
      logger.updateImageProgress('Calculating costs and finalizing');
    }

    // Estimate prompt tokens for cost calculation (gpt-image-1 doesn't return usage)
    const estimatedPromptTokens = Math.ceil(prompt.length / 4) // rough estimate: 4 chars per token
    
    // Log metrics using logger if provided
    if (logger) {
      const metrics = createImageMetrics(estimatedPromptTokens, 'high')
      
      if ('logImage' in logger) {
        // CompactLogger
        logger.logImage(metrics)
      } else {
        // TieredLogger - will be handled in generation service
        logger.debug('Image generation completed', { tokens: estimatedPromptTokens, cost: metrics.cost })
      }
    }

    return {
      imageUrl: imageUrl,
      prompt: prompt,
      revisedPrompt: imageData.revised_prompt,
      tokens: {
        prompt: estimatedPromptTokens,
        completion: 0
      }
    }
  } catch (error: unknown) {
    console.error('❌ gpt-image-1 generation failed:', error)
    
    // Handle specific OpenAI errors
    const errorObj = error as { error?: { code?: string; message?: string } }
    if (errorObj?.error?.code === 'content_policy_violation') {
      throw new Error('Content not suitable for generation. Please try a different scene description.')
    }
    
    if (errorObj?.error?.code === 'rate_limit_exceeded') {
      throw new Error('Too many requests. Please wait a moment and try again.')
    }
    
    if (errorObj?.error?.code === 'insufficient_quota') {
      throw new Error('OpenAI quota exceeded. Please contact support.')
    }

    throw new Error('Failed to generate coloring page. Please try again.')
  }
}

export async function downloadImage(imageUrl: string): Promise<Buffer> {
  try {
    // Handle data URLs (base64) from gpt-image-1
    if (imageUrl.startsWith('data:image/')) {
      const base64Data = imageUrl.split(',')[1]
      const buffer = Buffer.from(base64Data, 'base64')
      return buffer
    }
    
    // Handle regular URLs (fallback for other models)
    const response = await fetch(imageUrl)
    if (!response.ok) {
      throw new Error(`Failed to download image: ${response.statusText}`)
    }

    const buffer = Buffer.from(await response.arrayBuffer())
    return buffer
  } catch (error) {
    console.error('❌ Image processing failed:', error)
    throw new Error('Failed to process generated image')
  }
}
